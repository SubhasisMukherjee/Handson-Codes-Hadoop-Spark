# target-dir must not exist beforehand. if it exists, the command while fail with the same error
# this command will create the directory while sqooping. 
# then would put the table data inside this directory as part files
# there would be no subfolder created inside target-dir with the table name, datafiles would be put directly inside target-dir
# if target-dir is not provided, sqoop will create a directory in the current working directory with the same name as table name

sqoop import \
--connect jdbc:mysql://ip-172-31-20-247/sqoopex \
--username sqoopuser \
--password NHkkP876rp \
--table user \
--target-dir sqoop_import_dir



# warehouse-dir may exist beforehand, if does not exist it will be created while sqooping
# during sqooping, a subfolder would be created inside the warehouse-dir with same name as the table name
# data would be put inside this subfolder as part files

sqoop import \
--connect jdbc:mysql://ip-172-31-20-247/sqoopex \
--username sqoopuser \
--password NHkkP876rp \
--table user \
--warehouse-dir sqoop_import_dir



# Selecting specific columns
# if the tablename directory already exists, sqoop will fail
# if we use --append option, it will append the new part files inside the same folder as the existing one
# if a column mentioned in the --column option is not there in the table, sqoop will fail

sqoop import \
--connect jdbc:mysql://ip-172-31-20-247/sqoopex \
--username sqoopuser \
--password NHkkP876rp \
--table user \
--columns "name,age,gender" \
--warehouse-dir sqoop_import_dir \
--append


# parallellism is controlled by number of mappers
# there will be that many number of part files as there are mappers, hence in the below case 6 part files will be created

sqoop import \
--connect jdbc:mysql://ip-172-31-20-247/sqoopex \
--username sqoopuser \
--password NHkkP876rp \
--table user \
--columns "name,age,gender" \
--warehouse-dir sqoop_import_dir \
--num-mappers 6


# Storing data in SequenceFiles, and setting the generated class name to com.sqoopex.userclass
# a java source file will be generated as userclass.java and stored in the path ./com/sqoopex/

sqoop import \
--connect jdbc:mysql://ip-172-31-20-247/sqoopex \
--username sqoopuser \
--password NHkkP876rp \
--table user \
--warehouse-dir sqoop_import_dir \
--class-name com.sqoopex.userclass \
--as-sequencefile


# Specifying the delimiters to use in a text-mode import
sqoop import \
--connect jdbc:mysql://ip-172-31-20-247/sqoopex \
--username sqoopuser \
--password NHkkP876rp \
--table user \
--warehouse-dir sqoop_import_dir \
--fields-terminated-by '\t' \
--lines-terminated-by '\n' \
--optionally-enclosed-by '\"'


# import data into hive directly. a table with the same name as the source table will be created in 'default' database
# to create the table in a specific database, mention the --hive-table option as 'database.table'
# if the hive table is precreated and the hive table has less number of columns than the mysql table, still the job will not fail, the #columns which are there in the hive table, will be populated
# if the hive table is precreated and the hive table has more number of columns than the mysql table, still the job will not fail, the #columns which are not there in the mysql table, will be populated with 'NULL' string

sqoop import \
--connect jdbc:mysql://ip-172-31-20-247/sqoopex \
--username sqoopuser \
--password NHkkP876rp \
--table user \
--hive-import \
--hive-table 'subhtech099501.usertbl'


# import record meeting specific creterion
# the number of part files would be same as number of mappers, even if some files are empty
sqoop import \
--connect jdbc:mysql://ip-172-31-20-247/sqoopex \
--username sqoopuser \
--password NHkkP876rp \
--table user \
--warehouse-dir sqoop_import_dir \
--where "age>=14"


# seting splitting column
sqoop import \
--connect jdbc:mysql://ip-172-31-20-247/sqoopex \
--username sqoopuser \
--password NHkkP876rp \
--table user \
--warehouse-dir sqoop_import_dir \
--split-by age


# incremental import on user_id column
# append mode is used in --incremental when table has continually rows being added
# --last-value has the value which has been already imported
# at the end of an incremental import, the value which should be specified as --last-value for a subsequent import is printed to the screen

sqoop import \
--connect jdbc:mysql://ip-172-31-20-247/sqoopex \
--username sqoopuser \
--password NHkkP876rp \
--table user \
--warehouse-dir sqoop_import_dir \
--incremental append \
--check-column user_id \
--last-value 6

# output 
18/10/22 05:29:53 INFO tool.ImportTool: Incremental import complete! To run another incremental import of all data following this import, supply the following arguments:
18/10/22 05:29:53 INFO tool.ImportTool:  --incremental append
18/10/22 05:29:53 INFO tool.ImportTool:   --check-column user_id
18/10/22 05:29:53 INFO tool.ImportTool:   --last-value 7
18/10/22 05:29:53 INFO tool.ImportTool: (Consider saving this with 'sqoop job --create')


# import all the tables present in retail_db database of mysql
sqoop import-all-tables \
--connect jdbc:mysql://ip-172-31-20-247/sqoopex \
--username sqoopuser \
--password NHkkP876rp \
--warehouse-dir sqoop_import_dir

# above command got an error "ERROR tool.ImportAllTablesTool: Encountered IOException running import job: java.io.IOException: #Generating splits for a textual index column allowed only in case of "-Dorg.apache.sqoop.splitter.allow_text_splitter=true" property #passed as a parameter". It looks like it is trying to do an internal split by, trying to mitigate this with --autoreset-to-one-mapper
# need to delete the table folders present from previous command

sqoop import-all-tables \
--connect jdbc:mysql://ip-172-31-20-247/sqoopex \
--username sqoopuser \
--password NHkkP876rp \
--warehouse-dir sqoop_import_dir \
--autoreset-to-one-mapper

# the above didnt solve the issue, hence trying -Dorg.apache.sqoop.splitter.allow_text_splitter=true
sqoop import-all-tables \
-D org.apache.sqoop.splitter.allow_text_splitter=true \
--connect jdbc:mysql://ip-172-31-20-247/retail_db \
--username sqoopuser \
--password NHkkP876rp \
--warehouse-dir sqoop_import_dir \
--autoreset-to-one-mapper

# import all table, excluding a list of tables
sqoop import-all-tables \
-D org.apache.sqoop.splitter.allow_text_splitter=true \
--connect jdbc:mysql://ip-172-31-20-247/retail_db \
--username sqoopuser \
--password NHkkP876rp \
--warehouse-dir sqoop_import_dir \
--autoreset-to-one-mapper \
--exclude-tables countryregion,countryregioncurrency,creditcard,culture,currency,currencyrate,customer,customeraddress,customers,databaselog,dataframe_cust,department,departments,document,emp,employee,errorlog,illustration,individual,jobcandidate,location,order_items,order_items_csm,order_items_npk,orders,orders_csm,orders_csm_pk,orders_csm_stg,orders_test,productcategory,productcosthistory,productdescription,productdocument,productinventory,productlistpricehistory,productmodel,productmodelillustration,productmodelproductdescriptionculture,productphoto,productproductphoto,productreview,products,productsubcategory,productvendor,purchaseorderdetail,purchaseorderheader,salesorderdetail,salesorderheader,salesorderheadersalesreason,salesperson,salespersonquotahistory,salesreason,salestaxrate,salesterritory,salesterritoryhistory,scrapreason


# importing the above tables in Hive, in subhtech099501 database
sqoop import-all-tables \
-D org.apache.sqoop.splitter.allow_text_splitter=true \
--connect jdbc:mysql://ip-172-31-20-247/retail_db \
--username sqoopuser \
--password NHkkP876rp \
--warehouse-dir sqoop_import_dir \
--autoreset-to-one-mapper \
--hive-import \
--hive-overwrite \
--create-hive-table \
--hive-database subhtech099501 \
--exclude-tables countryregion,countryregioncurrency,creditcard,culture,currency,currencyrate,customer,customeraddress,customers,databaselog,dataframe_cust,department,departments,document,emp,employee,errorlog,illustration,individual,jobcandidate,location,order_items,order_items_csm,order_items_npk,orders,orders_csm,orders_csm_pk,orders_csm_stg,orders_test,productcategory,productcosthistory,productdescription,productdocument,productinventory,productlistpricehistory,productmodel,productmodelillustration,productmodelproductdescriptionculture,productphoto,productproductphoto,productreview,products,productsubcategory,productvendor,purchaseorderdetail,purchaseorderheader,salesorderdetail,salesorderheader,salesorderheadersalesreason,salesperson,salespersonquotahistory,salesreason,salestaxrate,salesterritory,salesterritoryhistory,scrapreason
